version: '3'
services:

  spark-master:
    image: spark:spark-3.3.1-hadoop-3
    container_name: spark-master
    ports:
      - 9090:8080
      - 7077:7077
    volumes:
      - ./workspace/note:/opt/shared_storage
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_MODE=master
    networks:
      - big-data    
  
  spark-worker-1:
    image: spark:spark-3.3.1-hadoop-3
    container_name: spark-worker-1
    ports:
      - 9091:8080
      - 7000:7000
    # If you find an environment variable that does not exist in Dockerfile and start-spark.sh, please read the official doc how to deploy spark standalone mode
    # in this case, i used SPARK_WORKER_CORES, SPARK_WORKER_MEMORY in this url: https://spark.apache.org/docs/latest/spark-standalone.html 
    # (at the time i write this docker-compose, version 3.3.1 is the latest version of spark)
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - SPARK_DRIVER_MEMORY=2G
      - SPARK_EXECUTOR_MEMORY=2G
      - SPARK_MODE=worker
      - SPARK_LOCAL_IP=spark-worker-1
    volumes:
      - ./workspace:/opt/shared_storage
    depends_on:
      - spark-master
    networks:
      - big-data
  
  spark-worker-2:
    image: spark:spark-3.3.1-hadoop-3
    container_name: spark-worker-2
    ports:
      - 9092:8080
      - 7001:7000
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - SPARK_DRIVER_MEMORY=2G
      - SPARK_EXECUTOR_MEMORY=2G
      - SPARK_MODE=worker
      - SPARK_LOCAL_IP=spark-worker-2
    volumes:
      - ./workspace:/opt/shared_storage
    depends_on:
      - spark-master
    networks:
      - big-data
    
networks:
  big-data:
    external: true
