version: '3'
services:

  spark-master:
    image: spark:spark-3.3.1-hadoop-3
    ports:
      - 9090:8080
      - 7077:7077
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_MODE=master
    networks:
      - bigdatanet
  
  spark-worker-1:
    image: spark:spark-3.3.1-hadoop-3
    ports:
      - 9091:8080
      - 7000:7000
    # If you find an environment variable that does not exist in Dockerfile and start-spark.sh, please read the official doc how to deploy spark standalone mode
    # in this case, i used SPARK_WORKER_CORES, SPARK_WORKER_MEMORY in this url: https://spark.apache.org/docs/latest/spark-standalone.html 
    # (at the time i write this docker-compose, version 3.3.1 is the latest version of spark)
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_MODE=worker
      - SPARK_LOCAL_IP=spark-worker-1
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    networks:
      - bigdatanet
  
  spark-worker-2:
    image: spark:spark-3.3.1-hadoop-3
    ports:
      - 9092:8080
      - 7001:7000
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_MODE=worker
      - SPARK_LOCAL_IP=spark-worker-2
    volumes:
      - ./apps:/opt/spark-apps
      - ./data:/opt/spark-data
    networks:
      - bigdatanet
  
  jupyter_lab:
    image: jupyterlab:python-3.10.6-jdk-11.10.16
    ports:
      - 8888:8888
      - 4040:4040
    volumes:
      - ./data:/opt/jupyterlab/data
      - ./apps:/opt/jupyterlab/apps
    networks:
      - bigdatanet

networks:
  bigdatanet: